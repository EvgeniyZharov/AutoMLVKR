import logging
import pandas as pd
import joblib

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.tree import DecisionTreeRegressor

from Pipelines.BasePipeline import BasePipeline


class RegressionPipeline(BasePipeline):
    def __init__(self, st):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.

        :param st: –æ–±—ä–µ–∫—Ç Streamlit
        """
        self.title = "Regression"
        super().__init__(st, self.title)

        self.registry_models = {
            "LinearRegression": {
                "class": LinearRegression,
                "params": {},
                "name": "LinearRegression.pkl"
            },
            "GradientBoostingRegressor": {
                "class": GradientBoostingRegressor,
                "params": {"n_estimators": 100, "learning_rate": 0.1, "random_state": 42},
                "name": "GradientBoostingRegressor.pkl"
            },
            "DecisionTreeRegressor": {
                "class": DecisionTreeRegressor,
                "params": {"random_state": 42},
                "name": "DecisionTreeRegressor.pkl"
            }
        }

        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        self.logger.info("RegressionPipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def get_data(self):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV-—Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –µ–≥–æ.

        :return: True, –µ—Å–ª–∏ —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω, –∏–Ω–∞—á–µ False
        """
        self.uploaded_file = self.st.file_uploader("\U0001F4C1 –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏", type=["csv"])
        if self.uploaded_file:
            self.df = pd.read_csv(self.uploaded_file)
            self.all_tables = self.df.columns.tolist()
            self.st.dataframe(self.df.head())
            self.logger.info("–§–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
            return True
        self.logger.warning("–§–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω")
        return False

    def train_models(self):
        """
        –û–±—É—á–∞–µ—Ç –≤—Å–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö.

        :return: None
        """
        features = [col for col in self.df.columns if col != self.target_col]
        X = self.df[features]
        y = self.df[self.target_col]
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        results = []

        for model_name in self.selected_models:
            model_cls = self.registry_models[model_name]["class"]
            params = self.registry_models[model_name]["params"]
            model = model_cls(**params)

            pipeline = Pipeline([
                ("scaler", StandardScaler()),
                ("model", model)
            ])
            pipeline.fit(X_train, y_train)
            y_pred = pipeline.predict(X_test)

            joblib.dump(pipeline, f"trained_models/{self.registry_models[model_name]['name']}")
            self.logger.info("–ú–æ–¥–µ–ª—å %s –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞", model_name)

            results.append({
                "Model": model_name,
                "RMSE": mean_squared_error(y_test, y_pred),
                "MAPE": mean_absolute_percentage_error(y_test, y_pred)
            })

        self.stat = pd.DataFrame(results)
        self.logger.info("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

    def make_predict(self):
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.

        :return: None
        """
        if "model" not in self.st.session_state:
            self.st.warning("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å.")
            self.logger.warning("–ú–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return

        val_file = self.st.file_uploader("\U0001F4C4 –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è", type=["csv"], key="val")
        if val_file:
            df_val = pd.read_csv(val_file)
            if self.st.button("\U0001F52E –°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"):
                preds = self.st.session_state.model.predict(df_val)
                df_val["Prediction"] = preds
                self.st.write("\U0001F4CA –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
                self.st.dataframe(df_val)
                self.logger.info("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã")

    def make_more_train(self):
        """
        –î–æ–æ–±—É—á–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

        :return: None
        """
        if "model" not in self.st.session_state:
            self.st.warning("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å.")
            self.logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è –±–µ–∑ –º–æ–¥–µ–ª–∏")
            return

        train_file = self.st.file_uploader("\U0001F4C4 –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è", type=["csv"], key="retrain")
        if train_file:
            df_new = pd.read_csv(train_file)
            features = [col for col in df_new.columns if col != self.target_col]
            X_new = df_new[features]
            y_new = df_new[self.target_col]

            if self.st.button("\U0001F501 –î–æ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"):
                model = self.st.session_state.model
                if hasattr(model, "partial_fit"):
                    model.partial_fit(X_new, y_new)
                    self.st.success("‚úÖ –ú–æ–¥–µ–ª—å –¥–æ–æ–±—É—á–µ–Ω–∞.")
                else:
                    model.fit(X_new, y_new)
                    self.st.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞ (—Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ —É—á–∏—Ç—ã–≤–∞–ª–∏—Å—å).")

                joblib.dump(model, self.st.session_state.model_title)
                self.st.success("üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
                self.logger.info("–ú–æ–¥–µ–ª—å –¥–æ–æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
